{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Outcomes\n",
    "#### 1. Apply various classification methods to a business problem\n",
    "#### 2. Compare results of k-nearest neighbors, logistic regression, decision trees, and support vector machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "#### 1. Understand data\n",
    "#### 2. Model data\n",
    "#### 3. Build Jupyter Notebook\n",
    "##### a. Demonstrate understanding of business problem\n",
    "##### b. Provide correct and concise interpretation of descriptive and inferential statistics\n",
    "##### c. Show findings (include actionable insights, next steps, and recommendations)\n",
    "#### 4. Submit website URL to public-facing GitHub respository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Modeling Deliverables\n",
    "#### 1. Use four classifier models (kNN, Decision Trees, Logistic Regression, SVM)\n",
    "#### 2. Clearly identify evaluation metrics\n",
    "#### 3. Appropriately interpret evaluation metrics\n",
    "#### 4. Display clear rationale for use of evaluation metrics\n",
    "#### 5. Appropriately compare the four models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework: Standard Process for Data Projects/Mining\n",
    "#### 1) Business Understanding: Background, Objectives, Success Criteria, Inventory of Resources/Requirements/Assumptions/Constraints/Risks/Contingencies/Terminology/Costs/Benefits, Data Mining Goals/Success Criteria\n",
    "\n",
    "#### 2) Data Understanding: Data Collection/Exploration/Quality Report\n",
    "\n",
    "#### 3) Data Preparation: Data Description/Inclusion/Exclusion/Attributes/Records, Merged Data, Reformatted Data\n",
    "\n",
    "#### 4) Modeling: Select Technique/Assumptions, Generate Test Designs, Build Model/Parameter Settings/Model Descrption, Assess Model, Revise Parameter Settings\n",
    "\n",
    "#### 5) Evaluation: Evaluate Results/Assessment of Results w.r.t Business Success Criteria/Approved Models, Review Process, Determine Next Steps, List of Possible Action Decisions\n",
    "\n",
    "#### 6) Deployment: Plan Deployment, Plan Monitoring and Maintenance Plan, Produce Final Report/Final Presentation, Review Project/Experience Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started: Use Dataset Related to \n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1: Understanding the Data\n",
    "\n",
    "Examining the **Materials and Methods** section of the paper, it appears the dataset is related to 17 campaigns that occurred between May 2008 and November 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2: Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First importing all libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import math \n",
    "import scipy.stats as stats\n",
    "import scipy.optimize\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from random import shuffle, seed\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import set_config\n",
    "from random import shuffle, seed\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, precision_recall_curve, roc_curve, f1_score, roc_auc_score\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next establishing settings for viewing plots\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting diagram \n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using pandas to read in the dataset bank-additional-full.csv\n",
    "# Assigning to a meaningful variable name\n",
    "\n",
    "Bank_Full_DF = pd.read_csv('bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking pandas read\n",
    "Bank_Full_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3: Examining the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring dataset by columns\n",
    "Bank_Full_DF.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring dataset by shape\n",
    "Bank_Full_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring dataset by info\n",
    "Bank_Full_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring data set by describe\n",
    "Bank_Full_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining sum of non-values by column\n",
    "# Determined no null values\n",
    "Bank_Full_DF.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bank Client Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Full_DF['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'unknown' values for categorical variables 'loan', 'housing', 'education', 'marital', 'job'\n",
    "# Lack of contribution to meaningful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop1 = Bank_Full_DF[Bank_Full_DF['loan'].str.contains('unknown')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop2 = Drop1[Drop1['housing'].str.contains('unknown')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop3 = Drop2[Drop2['education'].str.contains('unknown')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop4 = Drop3[Drop3['marital'].str.contains('unknown')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5 = Drop4[Drop4['job'].str.contains('unknown')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking variables\n",
    "Drop5['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['marital'].replace({\"divorced\": \"divorced_widowed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of new data frame\n",
    "Drop5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columns Containing Last Contacted Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['contact'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop5['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to \"Attribute Information\",'duration' is last contact duration, in seconds \n",
    "# This input should only be included for benchmark purposes \n",
    "# Should be discarded if the intention is to have a realistic predictive model\n",
    "# Dropping duration column\n",
    "Drop6 = Drop5.drop([\"duration\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking new data frame\n",
    "Drop6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking new data frame\n",
    "Drop6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columns Containing Other Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop6['campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop6['pdays'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating new column for pdays\n",
    "####### Coercing column for pdays into a new, future dummy variable column (Yes/No). According to \"Attribute Information\",'pdays' column is number of days that passed by after client was last contacted from a previous campaign (\"999\" means client was not previously contacted, all other numerical values emans client was previously contacted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop6['pdays'].sort_values().head(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop6['Contact_In_Prior_Campaign'] = Drop6['pdays'].replace({999: \"no\",\n",
    "                                                             0: \"yes\", \n",
    "                                                             1: \"yes\",\n",
    "                                                             2: \"yes\",\n",
    "                                                             3: \"yes\",\n",
    "                                                             4: \"yes\",\n",
    "                                                             5: \"yes\",\n",
    "                                                             6: \"yes\",\n",
    "                                                             7: \"yes\", \n",
    "                                                             8: \"yes\", \n",
    "                                                             9: \"yes\",\n",
    "                                                             10: \"yes\", \n",
    "                                                             11: \"yes\", \n",
    "                                                             12: \"yes\", \n",
    "                                                             13: \"yes\",\n",
    "                                                             14: \"yes\", \n",
    "                                                             15: \"yes\",\n",
    "                                                             16: \"yes\",\n",
    "                                                             17: \"yes\",\n",
    "                                                             18: \"yes\",\n",
    "                                                             19: \"yes\",\n",
    "                                                             20: \"yes\",\n",
    "                                                             21: \"yes\",\n",
    "                                                             22: \"yes\", \n",
    "                                                             23: \"yes\", \n",
    "                                                             24: \"yes\",\n",
    "                                                             25: \"yes\", \n",
    "                                                             26: \"yes\", \n",
    "                                                             27: \"yes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop6['Contact_In_Prior_Campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7 = Drop6.drop(['pdays'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columns Containing Other Attributes (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['previous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['poutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columns Containing Social and Economic Context Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['emp.var.rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['emp.var.rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['cons.price.idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['cons.conf.idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop7['euribor3m'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Drop7['nr.employed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing For Duplicate Rows Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicated = Drop7.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = Duplicated.sort_values()\n",
    "sorted.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping discovered duplicates\n",
    "Drop8 = Drop7.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of new data set \n",
    "Drop8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming Columns for Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFRenamed = Drop8.rename({'age': 'Age', 'job': 'Job_Type', 'marital': 'Marital_Status',\n",
    "                         'education': 'Education', 'housing': 'Housing_Loan', \n",
    "                          'default': 'Credit_In_Default', 'loan': 'Personal_Loan', \n",
    "                          'contact':'Communication_Type', 'month': 'Last_Contact_Month', \n",
    "                          'day_of_week': 'Last_Contact_Day', 'campaign': 'Total_Times_Contacted', \n",
    "                          'pdays': 'Days_Since_Last_Contact', 'previous': 'Previous_Contacts_Performed',\n",
    "                          'poutcome': 'Previous_Outcome', 'emp.var.rate': 'Employment_Variation_Quarterly', \n",
    "                          'cons.price.idx': 'Consumer_Price_Monthly', 'cons.conf.idx': 'Consumer_Confidence_Monthly',\n",
    "                          'euribor3m': 'Euribor_3Month_Daily','nr.employed': 'Employees_Quarterly', 'y': 'Subscribed'}, axis = 1)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFRenamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,7))\n",
    "corr = DFRenamed.corr()\n",
    "sns.heatmap(corr, annot=True).set(title = 'Numeric Variables Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlations above .90 threshold include Euribor_3Month_Daily with Employment_Variation_Quarterly, Euribor_3Month_Daily with Employees_Quarterly,  and Employees_Quarterly with Employment_Variation_Quarterly.  Since these correlations are substantially high, it would be possible to drop particular columns to reduce dimensionality in the data set.\n",
    "\n",
    "##### Correlations above and below the .50 and -.50 threshold (and below .90), respectively, include Employment_Variation_Quarterly with Consumer_Price_Monthly (positive), Euribor_3Month_Daily with Consumer_Price_Monthly, Consumer_Price_Monthly with Consumer_Confidence_Monthly,   Days_Since_Last_Contact with Previous_Contacts_Performed (negative correlation),  Consumer_Price_Monthly with Employees_Quarterly, Previous_Contacts_Performed with Employees_Quarterly (negative correlation). These are variables to keep in mind during data exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dropping highly correlated features (> 0.90) to reduce dimensionality, and retaining Euribor_3Month_Daily Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop9 = DFRenamed.drop([\"Employment_Variation_Quarterly\"], axis=1)\n",
    "Drop10 = Drop9.drop([\"Employees_Quarterly\"], axis=1)\n",
    "Drop10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Outcome Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary outcome\n",
    "# Has the client subscribed a term deposit?\n",
    "\n",
    "Drop10['Subscribed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outcome variable with 0, 1\n",
    "Subscribed_Outcome = pd.DataFrame(Drop10[\"Subscribed\"].replace({\"no\": 0, \"yes\": 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subscribed_Outcome.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Subscribed_Outcome.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4: Understanding the Task - Will the Client Subscribe to a Bank Deposit?\n",
    "\n",
    "Business Goal:  To increase campaign efficiency, find a model that can explain if the client subscribes to the deposit. Identify the main characteristics that affect success to help management of human effort, phone calls, time, and other available resources. In addition, aid selection of a high quality and an affordable set of potential buying customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features (columns 1 - 7), prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 5: Encoding Data for Columns 1-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy dataframes for categorical variables\n",
    "dummiesjob = pd.get_dummies(Drop10[\"Job_Type\"])\n",
    "dummiesmarital = pd.get_dummies(Drop10[\"Marital_Status\"])\n",
    "dummieseducation = pd.get_dummies(Drop10[\"Education\"])\n",
    "dummiesdefault = pd.get_dummies(Drop10[\"Credit_In_Default\"])\n",
    "dummieshousing = pd.get_dummies(Drop10[\"Housing_Loan\"])\n",
    "dummiesloan = pd.get_dummies(Drop10[\"Personal_Loan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Data for Remaining Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiescommunication = pd.get_dummies(Drop10[\"Communication_Type\"])\n",
    "dummiesmonth = pd.get_dummies(Drop10[\"Last_Contact_Month\"])\n",
    "dummiesdayofweek = pd.get_dummies(Drop10[\"Last_Contact_Day\"])\n",
    "dummiesprioroutcome = pd.get_dummies(Drop10[\"Previous_Outcome\"])\n",
    "dummiescontactedprior = pd.get_dummies(Drop10[\"Contact_In_Prior_Campaign\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing Baseline Variables Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Categorical Variables in Data Frame\n",
    "CtgrcalVarbls = pd.concat([dummiesjob, dummiesmarital, dummieseducation, \n",
    "                           dummiesdefault, dummieshousing, dummiesloan, dummiescommunication,\n",
    "                           dummiesmonth, dummiesdayofweek, dummiesprioroutcome,\n",
    "                           dummiescontactedprior], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Numerical Variables in Data Frame\n",
    "NmrclVrbls = Drop10[['Age', 'Total_Times_Contacted', 'Previous_Contacts_Performed', 'Consumer_Price_Monthly',\n",
    "                     'Consumer_Confidence_Monthly','Euribor_3Month_Daily']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Numerical and Categorical Variables in Data Frame\n",
    "PreBaseline = pd.concat([CtgrcalVarbls,NmrclVrbls], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Outcome Variable to Data Frame\n",
    "Baseline = pd.concat([CtgrcalVarbls,NmrclVrbls, Subscribed_Outcome], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All Features Baseline Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for sklearn\n",
    "#Create indices for data frame and shuffle\n",
    "ShuffleM1 = list(range(0, len(Baseline)))\n",
    "seed(42)\n",
    "shuffle(ShuffleM1)\n",
    "ShuffleM1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 6: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = Baseline.drop(['Subscribed'], axis=1)\n",
    "y = Baseline['Subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 7: Establishing Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline With Logistic Regression for 56 features\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Accuracy\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Performance That Classifier Should Aim to Beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy score to beat is 88.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 8: Building Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating priority features via L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = Baseline.drop(['Subscribed'], axis=1)\n",
    "y = Baseline['Subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = []\n",
    "for C in Cs:\n",
    "    lgr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list.append(list(lgr.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coef_list, columns = X.columns)\n",
    "coef_df.index = Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "plt.semilogx(coef_df)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.grid()\n",
    "plt.legend(list(coef_df.columns));\n",
    "plt.title('Increasing Regularization on Baseline Model')\n",
    "plt.xlabel(\"Increasing 1/C\")\n",
    "plt.savefig('coefl1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After evaluation, top features are Contact_In_Prior_Campaign and Euribor_3Month_Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing Model Prior to Creating Data Frame for Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimized_Model = Drop10[['Contact_In_Prior_Campaign', 'Euribor_3Month_Daily', 'Subscribed']]\n",
    "Optimized_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contacted_Prior_Campaign = pd.DataFrame(Optimized_Model[\"Contact_In_Prior_Campaign\"].replace({\"no\": 0, \"yes\": 1}))\n",
    "Subscribed_Outcome = pd.DataFrame(Optimized_Model[\"Subscribed\"].replace({\"no\": 0, \"yes\": 1}))\n",
    "Euribor_Rate = pd.DataFrame(Optimized_Model['Euribor_3Month_Daily'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OptimizedDF = pd.concat([Euribor_Rate,Contacted_Prior_Campaign, Subscribed_Outcome], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OptimizedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=Drop10, x = 'Subscribed')\n",
    "plt.title('Count of target observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imbalanced Target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on the above results the baseline for \"yes\" subscribed is 11.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = OptimizedDF, x='Euribor_3Month_Daily', \n",
    "                y='Contact_In_Prior_Campaign',\n",
    "                hue='Subscribed')\n",
    "plt.title('Model Scatterplot: Euribor Rate by Contact In Prior Campaign')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On this scatter plot visualization for the Simple Model, in appears that if the client was contacted in a prior campaign, and the Euribor rate was below 2%, the client was more likely to subscribe.  This simple model will be compared with Logistic Regression, k-Nearest Neighbors, Decision Tree, and Support Vector Machine algorithms. Accuracy, the number of all correct predictions divided by the total number of the dataset, will be used as the evaluation metric to compare models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Frame for Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple_Model_Variables = Drop10[['Contact_In_Prior_Campaign','Euribor_3Month_Daily', 'Subscribed']]\n",
    "Simple_Model_Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New data frame with numeric dummy variables\n",
    "CtgrcalVarbls2 = dummiescontactedprior\n",
    "NmrclVrbls2 = Drop10[['Euribor_3Month_Daily']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Outcome Variable to Data Frame\n",
    "SimpleModel = pd.concat([CtgrcalVarbls2, NmrclVrbls2, Subscribed_Outcome], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SimpleModel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceData = SimpleModel.query('Subscribed == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = BalanceData.drop(['Subscribed'], axis=1)\n",
    "y = BalanceData['Subscribed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling problem of imbalanced data when comparing accuracy results. Accuracy will be used chosen as comparison metric as it may best capture the number of correct predictions against the total number of predictions - in a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_subscribed = len(SimpleModel[SimpleModel['Subscribed'] == 1])\n",
    "no_subscribed_indices = SimpleModel[SimpleModel.Subscribed == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(no_subscribed_indices, yes_subscribed, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_subscribed_indices = SimpleModel[SimpleModel.Subscribed == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample_indices = np.concatenate([yes_subscribed_indices,random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample = SimpleModel.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=under_sample, x = 'Subscribed')\n",
    "plt.title('Count of target observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling from balanced data set. Please note that results below will vary based on new sample. Please refer to the tables below for results (e.g., first recorded outcomes on training and test accuracies, coefficients, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for balanced data set\n",
    "X_under = under_sample.loc[:,under_sample.columns != 'Subscribed']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'Subscribed']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.25, random_state = 0)\n",
    "\n",
    "X = X_under \n",
    "y = y_under "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 9: Scoring the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Logistic Regression on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "logreg = LogisticRegression(multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Intercept': ['0.99', '', ''],\n",
    "     'Coefficients (Prior Contact, No Prior Contact, Euribor)': ['-0.45', '0.45', ' -0.20'],\n",
    "     'Thresholds (Prior Contact, No Prior Contact, Euribor)': ['2.18', '-2.18', '4.85']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreSimpleModelTable = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleModelTable = PreSimpleModelTable.set_index('Intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleModelTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model Coefficients Table\n",
    "##### In this model, the feature that has the most explanatory values in the outcome variable were the 'No Prior Contact' variable and the 'Prior Contact' variables. One can interpret that for the target of subscription, it might be best to contact targeted groups multiple times across campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining training accuracy for model\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 10: Setting Up Model for Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head())\n",
    "print('==============')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split with 25% of the data assigned as the test set\n",
    "#Set random_state = 42 to assure correct grading\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 5))])\n",
    "KNNBasic.fit(X_train, y_train)\n",
    "KNNVBasic_acc_train = KNNBasic.score(X_train, y_train)\n",
    "KNNBasic_acc_test = KNNBasic.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNVBasic_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to train was .1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split with 25% of the data assigned as the test set\n",
    "#Set random_state = 42 to assure correct grading\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = None, random_state = 42).fit(X_train, y_train)\n",
    "print(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_1 = dtree.get_depth()\n",
    "print(depth_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = dtree.score(X_train, y_train)\n",
    "test_acc = dtree.score(X_test, y_test)\n",
    "print(f'Training Accuracy: {train_acc: .3f}')\n",
    "print(f'Test Accuracy: {test_acc: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to train was .1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and fitting SVC Estimator\n",
    "svc_1 = SVC(kernel = 'linear').fit(X_train, y_train)\n",
    "support_vectors = svc_1.support_vectors_\n",
    "support_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuracy\n",
    "y_pred = svc_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "y_pred = svc_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to train was 7 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Type = ['Logistic Regression', 'kNN', 'Decision Tree', 'SVM']\n",
    "Training_Accuracy = [0.716, 0.733, 0.746, 0.715]\n",
    "Test_Accuracy = [0.587, 0.722, 0.724, 0.587]\n",
    "Train_Time_Sec = [.1, .1, .1, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=zip(Model_Type,Training_Accuracy,Test_Accuracy, Train_Time_Sec),columns=['Model','Training_Accuracy', 'Test_Accuracy', 'Train(Sec)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelComparisonTable = df1.set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelComparisonTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best performing model was the decision tree, with a test accuracy score of 72.4%. Closely following was the k-Nearest Neighbors model, with a test accuracy score of 72.2%.  These were lower test accuracy scores compared to baseline model, which included an optimized set of attributes (yet classes were imbalanced in analysis). The Logistic Regression model listed in the above table would serve as a better baseline (58.7% test accuracy), as classes were balanced in the analysis.  Thus, when compared to baseline, the decision tree, with a test accuracy score of 72.4%, was an improvement. It can also be noted that the slowest model to train was the Support Vector Machine model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 11: Improving the Model\n",
    "#### Optimal feature variables were found early in the analysis via logistic regression. These features were the following:  \n",
    "\n",
    "##### 1) The dichotomous variable describing whether a client was contacted in a prior campaign \n",
    "##### 2) The continuous variable describing the Euribor interest rate\n",
    "\n",
    "###### Test accuracy was 58.7%. \n",
    "\n",
    "###### Based on such feature variables, the accuracy of the models for Logistic Regression, k-Nearest Neighbors, Decision Tree, and Support Vector Machine were compared. The decision tree performed the best when comparing each of these models, with an accuracy score of 72.4%. Thus, the decision tree parameters will be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 11: Improving the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing parameters for the decision tree model with various cross validation methods\n",
    "params = {'max_depth': [2,5,10],\n",
    "         'min_samples_split': [.1,.2,.05],\n",
    "          'criterion': ['gini', 'gini', 'gini'],\n",
    "          'min_samples_leaf': [1,10,20]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=params).fit(X_train, y_train)\n",
    "grid_train_acc = grid.score(X_train, y_train)\n",
    "grid_test_acc = grid.score(X_test, y_test)\n",
    "best_params = grid.best_params_\n",
    "print(f'Training Accuracy: {grid_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {grid_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV\n",
    "random = RandomizedSearchCV(DecisionTreeClassifier(random_state = 42), params).fit(X_train, y_train)\n",
    "random_train_acc = random.score(X_train, y_train)\n",
    "random_test_acc = random.score(X_test, y_test)\n",
    "best_params = random.best_params_\n",
    "print(f'Training Accuracy: {random_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {random_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time .1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HalvingGridSearchCV\n",
    "halving = HalvingGridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=params).fit(X_train, y_train)\n",
    "halving_train_acc = halving.score(X_train, y_train)\n",
    "halving_test_acc = halving.score(X_test, y_test)\n",
    "best_params = halving.best_params_\n",
    "print(f'Training Accuracy: {halving_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {halving_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HalvingRandomSearchCV\n",
    "halvingrand = HalvingRandomSearchCV(DecisionTreeClassifier(random_state = 42), params).fit(X_train, y_train)\n",
    "halvingrand_train_acc = halvingrand.score(X_train, y_train)\n",
    "halvingrand_test_acc = halvingrand.score(X_test, y_test)\n",
    "best_params = halvingrand.best_params_\n",
    "print(f'Training Accuracy: {halvingrand_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {halvingrand_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCVModel = ['Grid', 'Randomized', 'HalvingGrid', 'HalvingRandom']\n",
    "Performance_Sec = [5, .1, 5, 5]\n",
    "Training_Accuracy = [0.733, 0.739, 0.716, 0.740]\n",
    "Test_Accuracy = [0.738, 0.727, 0.700, 0.735]\n",
    "Max_Depth = [10, 10, 2, 5]\n",
    "Min_Samples_Leaf = [1, 10, 20, 1]\n",
    "Min_Samples_Split = [0.1, 0.05, 0.1, 0.05]\n",
    "Criterion = [\"Gini\", \"Gini\", \"Gini\", \"Gini\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=zip(SearchCVModel,Performance_Sec,Training_Accuracy,Test_Accuracy, Max_Depth, Min_Samples_Leaf, Min_Samples_Split),columns=['CVModel','Performance_Seconds','Training_Accuracy','Test_Accuracy', 'Depth(Max)', 'Leaf(Min)', 'Split(Min)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeTable = df.set_index('CVModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Visualization of Decision Tree Results\n",
    "kwargs= dict (linestyle='dashed', color=['red', 'green'], linewidth=1.2)\n",
    "line_plot = df.plot(y = ['Training_Accuracy','Test_Accuracy'], figsize= (10,6),**kwargs ) \n",
    "line_plot.set_title('Accuracy Line Plot (Test & Train)')\n",
    "line_plot.grid()\n",
    "plt.xlim([0,3])\n",
    "line_plot.set_xlabel('0.0: GridSearchCV, 1.0: RandomizedSearchCV, 2.0: HalvingGridSearchCV, 3.0: HalvingRandomSearchCV'),\n",
    "line_plot.set_ylabel('Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV performs best with a test accuracy of 73.8%. Training accuracy was lower than test accuracy (73.3%), which is an indication that the model was not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "plt.subplots(figsize=(18,19))\n",
    "clf = DecisionTreeClassifier(max_depth = 10, min_samples_leaf=1, min_samples_split = 0.10,\n",
    "                             random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Above is the best performing model, the decision tree with the following parameters (determined by GridSearchCV):  \n",
    "\n",
    "#### max_depth = 10, min_samples_leaf=1, min_samples_split = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Business Understanding: \n",
    "\n",
    "### The analyzed data set is from a Portuguese retail bank, and was initially gathered to observe the effects of financial crisis. Currently, the data set will be used for classification purposes in order to understand relevant features to long-term bank subscriptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Understanding:\n",
    "\n",
    "### Examining the **Materials and Methods** section of the paper, it appears the dataset is related to 17 campaigns that occurred between May 2008 and November 2010. It also appears that 20 attributes are included, in the categories of bank client data, social and economic attributes, and additional campaign attributes.\n",
    "\n",
    "### The main question is one of predicting whether or not a client will subscribe to a long-term bank deposit. The business goal is to increase campaign efficiency via finding a model that can explain if the client subscribes the deposit. Identifying the main characteristics that affect success can help management of human effort, phone calls, time, and other available resources. In addition, this can aid in selection of a high quality and an affordable set of potential buying customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Preparation\n",
    "\n",
    "### Data exploration and analysis included 20 initial attributes. While carefully examining the data features, the following actions occurred:\n",
    "\n",
    "#### - 'Unknown' values for categorical variables 'loan', 'housing', 'education', 'marital', 'job' were removed for lack of contribution to meaningful results\n",
    "\n",
    "#### - Created new column for pdays - coerced column for pdays column into a new, dummy variable column (Yes/No). According to \"Attribute Information\",'pdays' column is number of days that passed by after client was last contacted from a previous campaign (\"999\" means client was not previously contacted, all other numerical values means client was previously contacted)\n",
    "\n",
    "#### - Euribor_3Month_Daily feature was retained while highly correlated features (> 0.90) were removed to reduce dimensionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Modeling:\n",
    "\n",
    "### All remaining features were dummy coded if not continuous, and evaluated though Logistic Regression. Priority features were determined through L1 regularization. \n",
    "\n",
    "### The top two features were whether the client was contacted in a prior campaign and the numerical inter-bank interest rate (Euribor).\n",
    "\n",
    "#### Data were properly balanced and accuracy was chosen as comparison metric for model comparison. The reason was accuracy might best capture prediction in a binary classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluation\n",
    "\n",
    "### In this model, the feature that had the most explanatory values in the outcome variable were the 'No Prior Contact' variable and the 'Prior Contact' variables. One can interpret that for the target of subscription, it might be best to contact targeted groups multiple times across campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Key Features and Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SimpleModelTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decision tree, and parameters found through GridSearchCV, performed best -  with a test accuracy of 73.8%. Training accuracy was lower than test accuracy (73.3%), which was an indication that the training model was not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelComparisonTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Decision Tree Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Deployment\n",
    "\n",
    "### From this particular analysis, it appears that if the client was contacted in a prior campaign, and the current Euribor rate was below 2%, the client was more likely to subscribe to a long-term bank deposit. \n",
    "\n",
    "### Interestingly, it appears the inter-bank interest rate (Euribor), rather than characteristics of clients, contribute more to the agreement to subscribe to a long-term bank deposit. \n",
    "\n",
    "### Proceeding forward, it seems telemarketing calls should be made when the Euribor is low. Any target or priority individuals should also be called across campaigns to increase likelihood of subscription. The next step is to determine which priority clients need to be called across campaigns. In addition, methods need to be devised to make calls according to the fluctuating Euribor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
